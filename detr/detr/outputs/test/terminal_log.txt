Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: b9d644e69a1c41f60d4455e6dc4bc05c26788179, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=10, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2600 s / it)
Epoch [0] Train - Loss: 40.9623, Class Error: 91.23
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 443, in <module>
  File "C:\DETR\detr\main.py", line 443, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 366, in main
  File "C:\DETR\detr\main.py", line 366, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 34, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 34, in train_one_epoch
        samples_depth = samples_depth.to(device)samples_depth = samples_depth.to(device)

                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\util\misc.py", line 302, in to
  File "C:\DETR\detr\util\misc.py", line 302, in to
        cast_tensor = self.tensors.to(device)cast_tensor = self.tensors.to(device)

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

KeyboardInterruptKeyboardInterrupt

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: b9d644e69a1c41f60d4455e6dc4bc05c26788179, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2585 s / it)
Epoch [0] Train - Loss: 40.9623, Class Error: 91.23
Test: Total time: 0:00:18 (0.3788 s / it)
Accumulating evaluation results...
DONE (t=0.09s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
coco_evaluator.coco_eval['bbox'].stats: [7.24710152e-09 7.24710152e-08 0.00000000e+00 0.00000000e+00
 4.31415691e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
 7.54830918e-06 0.00000000e+00 2.88350634e-05 0.00000000e+00]
Epoch [0] Val - AP: 0.000, AP50: 0.000, AP75: 0.000, AR: 0.000, Loss: 52.8859
Validation score increased (-100000.000000 --> 0.000000).  Saving model ...
Training time 0:00:32
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================


================================================================================
PRETRAINED WEIGHTS VERIFICATION
================================================================================

[1] Checkpoint Information:
  Total keys in checkpoint: 458
  Total parameters in model: 532

[2] Key Matching Status:
  ‚úÖ Matched keys: 434
  ‚ùå Missing in checkpoint: 98
  ‚ö†Ô∏è  Unexpected in checkpoint: 24

[3] Critical Components Check:
  Backbone: 265/265 keys matched
  Encoder: 48/144 keys matched
  Decoder: 110/110 keys matched

[4] Weight Values Verification:
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 445, in <module>
  File "C:\DETR\detr\main.py", line 445, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 344, in main
  File "C:\DETR\detr\main.py", line 344, in main
        verify_pretrained_weights(model_without_ddp, checkpoint, args)verify_pretrained_weights(model_without_ddp, checkpoint, args)

  File "C:\DETR\detr\module.py", line 154, in verify_pretrained_weights
  File "C:\DETR\detr\module.py", line 154, in verify_pretrained_weights
        is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)

                            ^^^^^^^^^^

NameErrorNameError: : name 'torch' is not definedname 'torch' is not defined

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================


================================================================================
PRETRAINED WEIGHTS VERIFICATION
================================================================================

[1] Checkpoint Information:
  Total keys in checkpoint: 458
  Total parameters in model: 532

[2] Key Matching Status:
  ‚úÖ Matched keys: 434
  ‚ùå Missing in checkpoint: 98
  ‚ö†Ô∏è  Unexpected in checkpoint: 24

[3] Critical Components Check:
  Backbone: 265/265 keys matched
  Encoder: 48/144 keys matched
  Decoder: 110/110 keys matched

[4] Weight Values Verification:
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 445, in <module>
  File "C:\DETR\detr\main.py", line 445, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 344, in main
  File "C:\DETR\detr\main.py", line 344, in main
        verify_pretrained_weights(model_without_ddp, checkpoint, args)verify_pretrained_weights(model_without_ddp, checkpoint, args)

  File "C:\DETR\detr\module.py", line 154, in verify_pretrained_weights
  File "C:\DETR\detr\module.py", line 154, in verify_pretrained_weights
        is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)

                            ^^^^^^^^^^

UnboundLocalErrorUnboundLocalError: : cannot access local variable 'torch' where it is not associated with a valuecannot access local variable 'torch' where it is not associated with a value

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================


================================================================================
PRETRAINED WEIGHTS VERIFICATION
================================================================================

[1] Checkpoint Information:
  Total keys in checkpoint: 458
  Total parameters in model: 532

[2] Key Matching Status:
  ‚úÖ Matched keys: 434
  ‚ùå Missing in checkpoint: 98
  ‚ö†Ô∏è  Unexpected in checkpoint: 24

[3] Critical Components Check:
  Backbone: 265/265 keys matched
  Encoder: 48/144 keys matched
  Decoder: 110/110 keys matched

[4] Weight Values Verification:
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 445, in <module>
  File "C:\DETR\detr\main.py", line 445, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 344, in main
  File "C:\DETR\detr\main.py", line 344, in main
        verify_pretrained_weights(model_without_ddp, checkpoint, args)verify_pretrained_weights(model_without_ddp, checkpoint, args)

  File "C:\DETR\detr\module.py", line 155, in verify_pretrained_weights
  File "C:\DETR\detr\module.py", line 155, in verify_pretrained_weights
        is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)

                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

RuntimeErrorRuntimeError: : Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Loading pretrained weights...
Missing keys (new parameters): 74 keys
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_weight
  - transformer.encoder.layers.0.self_attn.depth_attn.in_proj_bias
  - transformer.encoder.layers.0.self_attn.depth_attn.out_proj.weight
  ... and 71 more

Copying RGB Encoder weights to Depth Encoder layers
Depth Encoder initialized with RGB Encoder weights!
RGB input_proj, Encoder, Decoder parameters frozen!

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 6,311,424 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 6,859,612
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 6,311,424 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================


================================================================================
PRETRAINED WEIGHTS VERIFICATION
================================================================================

[1] Checkpoint Information:
  Total keys in checkpoint: 458
  Total parameters in model: 532

[2] Key Matching Status:
  ‚úÖ Matched keys: 434
  ‚ùå Missing in checkpoint: 98
  ‚ö†Ô∏è  Unexpected in checkpoint: 24

[3] Critical Components Check:
  Backbone: 265/265 keys matched
  Encoder: 48/144 keys matched
  Decoder: 110/110 keys matched

[4] Weight Values Verification:
  Backbone weights match: True

  Checkpoint Encoder (in_proj -> q):
    Weight shape: torch.Size([256, 256])
    Weight mean: 0.000039
    Weight std: 0.058909

  Decoder weights match: True
    Weight std: 0.053688

[5] Depth Encoder Check:

[6] Missing Keys Analysis:
  Sample missing keys (first 10):
    1. transformer.encoder.layers.5.self_attn.depth_attn.out_proj.weight
    2. transformer.encoder.layers.5.self_attn.depth_attn.out_proj.bias
    3. transformer.encoder.layers.0.self_attn.depth_attn.out_proj.bias
    4. transformer.encoder.layers.3.self_attn.rgb_attn.out_proj.bias
    5. transformer.encoder.layers.0.self_attn.rgb_attn.in_proj_weight
    6. transformer.encoder.layers.1.norm2_depth.bias
    7. transformer.encoder.layers.1.norm1_depth.bias
    8. transformer.encoder.layers.4.self_attn.rgb_attn.in_proj_weight
    9. transformer.encoder.layers.1.linear2_depth.bias
    10. transformer.encoder.layers.1.norm2_depth.weight

  Missing keys by category:
    Depth-related: 74
    Fusion-related: 0
    Other: 24

[7] Overall Assessment:
================================================================================


================================================================================
PRETRAINED WEIGHTS VERIFICATION
================================================================================

[1] Checkpoint Information:
  Total keys in checkpoint: 458
  Total parameters in model: 532

[2] Key Matching Status:
  ‚úÖ Matched keys: 434
  ‚ùå Missing in checkpoint: 98
  ‚ö†Ô∏è  Unexpected in checkpoint: 24

[3] Critical Components Check:
  Backbone: 265/265 keys matched
  Encoder: 48/144 keys matched
  Decoder: 110/110 keys matched

[4] Weight Values Verification:
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 445, in <module>
  File "C:\DETR\detr\main.py", line 445, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 344, in main
  File "C:\DETR\detr\main.py", line 344, in main
        verify_pretrained_weights(model_without_ddp, checkpoint, args)verify_pretrained_weights(model_without_ddp, checkpoint, args)

  File "C:\DETR\detr\module.py", line 394, in verify_pretrained_weights
  File "C:\DETR\detr\module.py", line 394, in verify_pretrained_weights
        is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)is_same = torch.allclose(model_weight, checkpoint_weight, atol=1e-6)

                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

RuntimeErrorRuntimeError: : Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 402, in <module>
  File "C:\DETR\detr\main.py", line 402, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 299, in main
  File "C:\DETR\detr\main.py", line 299, in main
        print(aaa)print(aaa)

                    ^^^^^^

NameErrorNameError: : name 'aaa' is not definedname 'aaa' is not defined

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
transformer.encoder.layers.0.self_attn.in_proj_weight -> transformer.encoder.layers.0.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.0.self_attn.in_proj_bias -> transformer.encoder.layers.0.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.0.self_attn.out_proj.weight -> transformer.encoder.layers.0.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.0.self_attn.out_proj.bias -> transformer.encoder.layers.0.self_attn.rgb_attn.out_proj.bias
transformer.encoder.layers.1.self_attn.in_proj_weight -> transformer.encoder.layers.1.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.1.self_attn.in_proj_bias -> transformer.encoder.layers.1.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.1.self_attn.out_proj.weight -> transformer.encoder.layers.1.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.1.self_attn.out_proj.bias -> transformer.encoder.layers.1.self_attn.rgb_attn.out_proj.bias
transformer.encoder.layers.2.self_attn.in_proj_weight -> transformer.encoder.layers.2.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.2.self_attn.in_proj_bias -> transformer.encoder.layers.2.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.2.self_attn.out_proj.weight -> transformer.encoder.layers.2.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.2.self_attn.out_proj.bias -> transformer.encoder.layers.2.self_attn.rgb_attn.out_proj.bias
transformer.encoder.layers.3.self_attn.in_proj_weight -> transformer.encoder.layers.3.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.3.self_attn.in_proj_bias -> transformer.encoder.layers.3.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.3.self_attn.out_proj.weight -> transformer.encoder.layers.3.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.3.self_attn.out_proj.bias -> transformer.encoder.layers.3.self_attn.rgb_attn.out_proj.bias
transformer.encoder.layers.4.self_attn.in_proj_weight -> transformer.encoder.layers.4.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.4.self_attn.in_proj_bias -> transformer.encoder.layers.4.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.4.self_attn.out_proj.weight -> transformer.encoder.layers.4.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.4.self_attn.out_proj.bias -> transformer.encoder.layers.4.self_attn.rgb_attn.out_proj.bias
transformer.encoder.layers.5.self_attn.in_proj_weight -> transformer.encoder.layers.5.self_attn.rgb_attn.in_proj_weight
transformer.encoder.layers.5.self_attn.in_proj_bias -> transformer.encoder.layers.5.self_attn.rgb_attn.in_proj_bias
transformer.encoder.layers.5.self_attn.out_proj.weight -> transformer.encoder.layers.5.self_attn.rgb_attn.out_proj.weight
transformer.encoder.layers.5.self_attn.out_proj.bias -> transformer.encoder.layers.5.self_attn.rgb_attn.out_proj.bias
Renamed 24 keys for RGB-Stream compatibility.
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 403, in <module>
  File "C:\DETR\detr\main.py", line 403, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 300, in main
  File "C:\DETR\detr\main.py", line 300, in main
        print(aaa)print(aaa)

                    ^^^^^^

NameErrorNameError: : name 'aaa' is not definedname 'aaa' is not defined

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.29s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 417, in <module>
  File "C:\DETR\detr\main.py", line 417, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 314, in main
  File "C:\DETR\detr\main.py", line 314, in main
        print(aaa)print(aaa)

                    ^^^^^^

NameErrorNameError: : name 'aaa' is not definedname 'aaa' is not defined

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=1, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='coco', coco_path='S:/coco/coco2017', coco_panoptic_path=None, remove_difficult=False, output_dir='DETR/detr/outputs/test', device='cuda', seed=42, resume='weights/detr-r50-e632da11.pth', start_epoch=0, eval=False, num_workers=0, world_size=1, dist_url='env://', lr_depth_encoder=0.0001, depth_path='S:/coco/coco2017_depth', use_depth=True, debug=True, val_split=True, patience=5, use_sharefusion=True, distributed=False)
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================

Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 470, in <module>
  File "C:\DETR\detr\main.py", line 470, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 367, in main
  File "C:\DETR\detr\main.py", line 367, in main
        print(aaa)print(aaa)

                    ^^^^^^

NameErrorNameError: : name 'aaa' is not definedname 'aaa' is not defined

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 15,780,864 / 15,780,864 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 49,559,132
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 15,780,864 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:19 (0.3983 s / it)
Epoch [0] Train - Loss: 35.9682, Class Error: 99.17
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 468, in <module>
  File "C:\DETR\detr\main.py", line 468, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 413, in main
  File "C:\DETR\detr\main.py", line 413, in main
        test_stats, coco_evaluator = evaluate(test_stats, coco_evaluator = evaluate(

                                                                  ^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
        return func(*args, **kwargs)return func(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 96, in evaluate
  File "C:\DETR\detr\engine.py", line 96, in evaluate
        for samples, samples_depth, targets in metric_logger.log_every(data_loader, 1000, header):for samples, samples_depth, targets in metric_logger.log_every(data_loader, 1000, header):

  File "C:\DETR\detr\util\misc.py", line 225, in log_every
  File "C:\DETR\detr\util\misc.py", line 225, in log_every
        for obj in iterable:for obj in iterable:

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
        data = self._next_data()data = self._next_data()

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
        data = self._dataset_fetcher.fetch(index)  # may raise StopIterationdata = self._dataset_fetcher.fetch(index)  # may raise StopIteration

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 50, in fetch
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 50, in fetch
        data = self.dataset.__getitems__(possibly_batched_index)data = self.dataset.__getitems__(possibly_batched_index)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 420, in __getitems__
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 420, in __getitems__
        return [self.dataset[self.indices[idx]] for idx in indices]return [self.dataset[self.indices[idx]] for idx in indices]

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 420, in <listcomp>
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 420, in <listcomp>
        return [self.dataset[self.indices[idx]] for idx in indices]return [self.dataset[self.indices[idx]] for idx in indices]

                        ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\datasets\coco.py", line 68, in __getitem__
  File "C:\DETR\detr\datasets\coco.py", line 68, in __getitem__
        img, depth_img, target = self._transforms(img, depth_img, target)img, depth_img, target = self._transforms(img, depth_img, target)

                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\datasets\transforms.py", line 368, in __call__
  File "C:\DETR\detr\datasets\transforms.py", line 368, in __call__
        image, depth, target = t(image, depth, target)image, depth, target = t(image, depth, target)

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\datasets\transforms.py", line 244, in __call__
  File "C:\DETR\detr\datasets\transforms.py", line 244, in __call__
        depth_img_resized, _ = resize(depth_img, None, size, self.max_size)depth_img_resized, _ = resize(depth_img, None, size, self.max_size)

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\datasets\transforms.py", line 106, in resize
  File "C:\DETR\detr\datasets\transforms.py", line 106, in resize
        rescaled_image = F.resize(image, size)rescaled_image = F.resize(image, size)

                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\functional.py", line 477, in resize
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\functional.py", line 477, in resize
        return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\_functional_pil.py", line 250, in resize
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\_functional_pil.py", line 250, in resize
        return img.resize(tuple(size[::-1]), interpolation)return img.resize(tuple(size[::-1]), interpolation)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\PIL\Image.py", line 2304, in resize
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\PIL\Image.py", line 2304, in resize
        return self._new(self.im.resize(size, resample, box))return self._new(self.im.resize(size, resample, box))

                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

KeyboardInterruptKeyboardInterrupt

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 7,890,432 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 8,438,620
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 7,890,432 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:13 (0.2619 s / it)
Epoch [0] Train - Loss: 36.5495, Class Error: 97.50
Test: Total time: 0:00:17 (0.3465 s / it)
Accumulating evaluation results...
DONE (t=0.10s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
coco_evaluator.coco_eval['bbox'].stats: [2.53481585e-06 1.67618212e-05 3.43612572e-07 0.00000000e+00
 1.09307784e-05 4.27464746e-06 0.00000000e+00 9.81280193e-05
 6.58212560e-04 0.00000000e+00 1.54555940e-03 1.11642743e-03]
Epoch [0] Val - AP: 0.000, AP50: 0.000, AP75: 0.000, AR: 0.001, Loss: 34.6951
Validation score increased (-100000.000000 --> 0.000003).  Saving model ...
Training time 0:00:31
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 15,780,864 / 15,780,864 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 49,559,132
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 15,780,864 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 487, in <module>
  File "C:\DETR\detr\main.py", line 487, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 410, in main
  File "C:\DETR\detr\main.py", line 410, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
        outputs = model(samples, samples_depth)outputs = model(samples, samples_depth)

                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\detr.py", line 90, in forward
  File "C:\DETR\detr\models\detr.py", line 90, in forward
        hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) 

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
        memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
        output, output_depth = layer(output, output_depth, src_mask=mask,output, output_depth = layer(output, output_depth, src_mask=mask,

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
        return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
        src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,

                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
        q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
        tgt_len, bsz, embed_dim = q.shapetgt_len, bsz, embed_dim = q.shape

                                                            ^^^^^^^^^^^^^^

AttributeErrorAttributeError: : 'NoneType' object has no attribute 'shape''NoneType' object has no attribute 'shape'

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 15,780,864 / 15,780,864 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 49,559,132
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 15,780,864 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 487, in <module>
  File "C:\DETR\detr\main.py", line 487, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 410, in main
  File "C:\DETR\detr\main.py", line 410, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
        outputs = model(samples, samples_depth)outputs = model(samples, samples_depth)

                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\detr.py", line 90, in forward
  File "C:\DETR\detr\models\detr.py", line 90, in forward
        hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) 

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
        memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
        output, output_depth = layer(output, output_depth, src_mask=mask,output, output_depth = layer(output, output_depth, src_mask=mask,

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
        return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
        src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,

                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
        q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
        tgt_len, bsz, embed_dim = q.shapetgt_len, bsz, embed_dim = q.shape

                                                            ^^^^^^^^^^^^^^

AttributeErrorAttributeError: : 'NoneType' object has no attribute 'shape''NoneType' object has no attribute 'shape'

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 15,780,864 / 15,780,864 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 49,559,132
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 15,780,864 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 487, in <module>
  File "C:\DETR\detr\main.py", line 487, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 410, in main
  File "C:\DETR\detr\main.py", line 410, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 36, in train_one_epoch
        outputs = model(samples, samples_depth)outputs = model(samples, samples_depth)

                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\detr.py", line 90, in forward
  File "C:\DETR\detr\models\detr.py", line 90, in forward
        hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) hs, attn_weights, _ = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1]) 

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 61, in forward
        memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)memory, memory_depth = self.encoder(src, src_depth, src_key_padding_mask=mask, pos=pos_embed, pos_depth=pos_embed_depth)

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 91, in forward
        output, output_depth = layer(output, output_depth, src_mask=mask,output, output_depth = layer(output, output_depth, src_mask=mask,

                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 199, in forward
        return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)return self.forward_post(src, src_depth, src_mask, src_key_padding_mask, pos, pos_depth)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
  File "C:\DETR\detr\models\sharefusion.py", line 141, in forward_post
        src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,src2, src_depth2, _, _ = self.self_attn(q, k, src, q_depth, k_depth, src_depth,attn_mask=src_mask,

                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)return self._call_impl(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)return forward_call(*args, **kwargs)

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
  File "C:\DETR\detr\models\sharefusion.py", line 353, in forward
        q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)q_dpt, k_dpt, v_dpt = self._project_qkv(query_depth, key_depth, value_depth, self.depth_attn)

                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
  File "C:\DETR\detr\models\sharefusion.py", line 401, in _project_qkv
        tgt_len, bsz, embed_dim = q.shapetgt_len, bsz, embed_dim = q.shape

                                                            ^^^^^^^^^^^^^^

AttributeErrorAttributeError: : 'NoneType' object has no attribute 'shape''NoneType' object has no attribute 'shape'

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 7,890,432 / 7,890,432 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 41,668,700
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 7,890,432 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:09 (0.1965 s / it)
Epoch [0] Train - Loss: 35.5691, Class Error: 95.65
Epoch: [1] Total time: 0:00:09 (0.1967 s / it)
Epoch [1] Train - Loss: 31.2621, Class Error: 92.11
Epoch: [2] Total time: 0:00:09 (0.1921 s / it)
Epoch [2] Train - Loss: 28.7813, Class Error: 91.15
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 487, in <module>
  File "C:\DETR\detr\main.py", line 487, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 410, in main
  File "C:\DETR\detr\main.py", line 410, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 57, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 57, in train_one_epoch
        losses.backward()losses.backward()

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\_tensor.py", line 581, in backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\_tensor.py", line 581, in backward
        torch.autograd.backward(torch.autograd.backward(

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
        _engine_run_backward(_engine_run_backward(

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
        return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward passreturn Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

KeyboardInterruptKeyboardInterrupt

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.29s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 7,890,432 / 7,890,432 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 41,668,700
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 7,890,432 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 487, in <module>
  File "C:\DETR\detr\main.py", line 487, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 410, in main
  File "C:\DETR\detr\main.py", line 410, in main
        train_stats = train_one_epoch(train_stats = train_one_epoch(

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\engine.py", line 57, in train_one_epoch
  File "C:\DETR\detr\engine.py", line 57, in train_one_epoch
        losses.backward()losses.backward()

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\_tensor.py", line 581, in backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\_tensor.py", line 581, in backward
        torch.autograd.backward(torch.autograd.backward(

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
        _engine_run_backward(_engine_run_backward(

  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
  File "C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
        return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward passreturn Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

KeyboardInterruptKeyboardInterrupt

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 7,890,432 / 7,890,432 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 41,668,700
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 7,890,432 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:09 (0.1935 s / it)
Epoch [0] Train - Loss: 35.1225, Class Error: 95.15
Test: Total time: 0:00:08 (0.1611 s / it)
Accumulating evaluation results...
DONE (t=0.10s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029
coco_evaluator.coco_eval['bbox'].stats: [3.78648474e-03 1.72353053e-02 3.48835215e-04 7.72686609e-07
 4.08624716e-03 3.27153500e-03 3.98550725e-03 9.00513285e-03
 1.19565217e-02 1.24378109e-04 4.81545559e-03 2.87380383e-02]
Epoch [0] Val - AP: 0.004, AP50: 0.017, AP75: 0.000, AR: 0.012, Loss: 32.2078
Validation score increased (-100000.000000 --> 0.003786).  Saving model ...
Training time 0:00:18
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.48s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
Debug mode: using subset of size 100
>>> Mode: Standard DETR (Loading directly)
    Missing keys: 74

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [93mPARTIAL[0m | 23,232,512 / 23,454,912 params
Input Proj (RGB)                         | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [92mALL TRAINABLE[0m | 7,890,432 / 7,890,432 params
Transformer Decoder                      | [92mALL TRAINABLE[0m | 9,473,024 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 41,668,700
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 7,890,432 trainable
Decoder: 9,473,024 params, 9,473,024 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:10 (0.2050 s / it)
Epoch [0] Train - Loss: 8.3875, Class Error: 27.54
Test: Total time: 0:00:08 (0.1633 s / it)
Accumulating evaluation results...
DONE (t=0.14s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784
coco_evaluator.coco_eval['bbox'].stats: [0.43828753 0.66723548 0.46069747 0.15509758 0.4708789  0.66604241
 0.3557089  0.52663551 0.55412477 0.23241519 0.57699942 0.78431785]
Epoch [0] Val - AP: 0.438, AP50: 0.667, AP75: 0.461, AR: 0.554, Loss: 8.0108
Validation score increased (-100000.000000 --> 0.438288).  Saving model ...
Training time 0:00:19
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
>>> Mode: Standard DETR (Loading directly)
    Missing keys: 74

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [90mALL FROZEN[0m | 0 / 7,890,432 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 548,188
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 0 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:05 (0.1138 s / it)
Epoch [0] Train - Loss: 7.4824, Class Error: 25.26
Test: Total time: 0:00:07 (0.1547 s / it)
Accumulating evaluation results...
DONE (t=0.15s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.828
coco_evaluator.coco_eval['bbox'].stats: [0.50097736 0.68774603 0.53309476 0.21143769 0.5502102  0.72420819
 0.40774514 0.58937879 0.61649282 0.30363319 0.65187762 0.8281157 ]
Epoch [0] Val - AP: 0.501, AP50: 0.688, AP75: 0.533, AR: 0.616, Loss: 7.6070
Validation score increased (-100000.000000 --> 0.500977).  Saving model ...
Training time 0:00:14
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.27s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 7,890,432 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 8,438,620
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 7,890,432 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2586 s / it)
Epoch [0] Train - Loss: 36.5495, Class Error: 97.50
Test: Total time: 0:00:17 (0.3453 s / it)
Accumulating evaluation results...
DONE (t=0.10s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
coco_evaluator.coco_eval['bbox'].stats: [2.53481585e-06 1.67618212e-05 3.43612572e-07 0.00000000e+00
 1.09307784e-05 4.27464746e-06 0.00000000e+00 9.81280193e-05
 6.58212560e-04 0.00000000e+00 1.54555940e-03 1.11642743e-03]
Epoch [0] Val - AP: 0.000, AP50: 0.000, AP75: 0.000, AR: 0.001, Loss: 34.6951
Validation score increased (-100000.000000 --> 0.000003).  Saving model ...
Training time 0:00:30
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
Traceback (most recent call last):
Traceback (most recent call last):
  File "C:\DETR\detr\main.py", line 507, in <module>
  File "C:\DETR\detr\main.py", line 507, in <module>
        main(args)main(args)

  File "C:\DETR\detr\main.py", line 200, in main
  File "C:\DETR\detr\main.py", line 200, in main
        model, criterion, postprocessors = build_model(args)model, criterion, postprocessors = build_model(args)

                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\__init__.py", line 6, in build_model
  File "C:\DETR\detr\models\__init__.py", line 6, in build_model
        return build(args)return build(args)

                      ^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\detr.py", line 355, in build
  File "C:\DETR\detr\models\detr.py", line 355, in build
        transformer = build_transformer_RGBD(args)  ## changes heretransformer = build_transformer_RGBD(args)  ## changes here

                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 451, in build_transformer_RGBD
  File "C:\DETR\detr\models\sharefusion.py", line 451, in build_transformer_RGBD
        return Transformer_RGBD(return Transformer_RGBD(

                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 16, in __init__
  File "C:\DETR\detr\models\sharefusion.py", line 16, in __init__
        encoder_layer = EncoderLayer_RGBD(d_model, nhead, dim_feedforward,encoder_layer = EncoderLayer_RGBD(d_model, nhead, dim_feedforward,

                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 104, in __init__
  File "C:\DETR\detr\models\sharefusion.py", line 104, in __init__
        self.self_attn = RGBD_MultiHeadAttention(d_model, nhead, dropout=dropout, args=args)self.self_attn = RGBD_MultiHeadAttention(d_model, nhead, dropout=dropout, args=args)

                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\DETR\detr\models\sharefusion.py", line 333, in __init__
  File "C:\DETR\detr\models\sharefusion.py", line 333, in __init__
        if args.use_learnable_fusion:if args.use_learnable_fusion:

              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AttributeErrorAttributeError: : 'Namespace' object has no attribute 'use_learnable_fusion''Namespace' object has no attribute 'use_learnable_fusion'. Did you mean: '. Did you mean: 'use_learnable_paramuse_learnable_param'?'?

Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717356
Using split validation dataset for train
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 7,890,432 / 15,780,876 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 8,438,620
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,876 params, 7,890,432 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2596 s / it)
Epoch [0] Train - Loss: 33.1952, Class Error: 89.70
Test: Total time: 0:00:17 (0.3469 s / it)
Accumulating evaluation results...
DONE (t=0.12s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025
coco_evaluator.coco_eval['bbox'].stats: [6.46072534e-03 2.28823455e-02 1.30381829e-07 0.00000000e+00
 3.36965504e-05 1.05146627e-02 4.75845411e-03 9.91092995e-03
 1.05978261e-02 0.00000000e+00 1.35524798e-03 2.53538676e-02]
Epoch [0] Val - AP: 0.006, AP50: 0.023, AP75: 0.000, AR: 0.011, Loss: 30.7731
Validation score increased (-100000.000000 --> 0.006461).  Saving model ...
Training time 0:00:31
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building standard Transformer (RGB only)...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
Debug mode: using subset of size 100
>>> Mode: Standard DETR (Loading directly)
    Missing keys: 74

================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [90mALL FROZEN[0m | 0 / 7,890,432 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 548,188
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 7,890,432 params, 0 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2559 s / it)
Epoch [0] Train - Loss: 28.9305, Class Error: 95.15
Test: Total time: 0:00:14 (0.2970 s / it)
Accumulating evaluation results...
DONE (t=0.22s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016
coco_evaluator.coco_eval['bbox'].stats: [5.57971611e-03 3.04645035e-02 1.64125534e-05 2.17670288e-05
 1.36399037e-03 1.03373721e-02 5.92944847e-03 7.32588567e-03
 7.48662025e-03 2.90215589e-04 3.13148789e-03 1.62579745e-02]
Epoch [0] Val - AP: 0.006, AP50: 0.030, AP75: 0.000, AR: 0.007, Loss: 32.8247
Validation score increased (-100000.000000 --> 0.005580).  Saving model ...
Training time 0:00:28
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.28s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 7,890,432 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 8,438,620
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 7,890,432 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:12 (0.2573 s / it)
Epoch [0] Train - Loss: 33.1952, Class Error: 89.70
Test: Total time: 0:00:17 (0.3529 s / it)
Accumulating evaluation results...
DONE (t=0.23s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025
coco_evaluator.coco_eval['bbox'].stats: [6.46072534e-03 2.28823455e-02 1.30381829e-07 0.00000000e+00
 3.36965504e-05 1.05146627e-02 4.75845411e-03 9.91092995e-03
 1.05978261e-02 0.00000000e+00 1.35524798e-03 2.53538676e-02]
Epoch [0] Val - AP: 0.006, AP50: 0.023, AP75: 0.000, AR: 0.011, Loss: 30.7731
Validation score increased (-100000.000000 --> 0.006461).  Saving model ...
Training time 0:00:31
Logging to: DETR/detr/outputs/test\terminal_log.txt
Not using distributed mode
git:
  sha: 5e9d1f99850dd4a27c27c2c2225350625c52bc0a, status: has uncommited changes, branch: main

>>> Building RGB-D Transformer with ShareFusion...
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\ryosu\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
number of params: 49717344
Using split validation dataset for train
loading annotations into memory...
Done (t=0.26s)
creating index...
index created!
Debug mode: using subset of size 100
Using split validation dataset for val
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Debug mode: using subset of size 100
Renamed 24 keys for RGB-Stream compatibility.
>>> RGB Stream weights loaded successfully.
>>> Initializing Depth Stream from RGB weights...
>>> Depth Stream initialized.
============================================================


================================================================================
Module Name                              | Status          | Details
--------------------------------------------------------------------------------
Backbone (ResNet)                        | [90mALL FROZEN[0m | 0 / 23,454,912 params
Input Proj (RGB)                         | [90mALL FROZEN[0m | 0 / 524,544 params
Input Proj (Depth)                       | [92mALL TRAINABLE[0m | 524,544 / 524,544 params
Transformer Encoder                      | [93mPARTIAL[0m | 7,890,432 / 15,780,864 params
Transformer Decoder                      | [90mALL FROZEN[0m | 0 / 9,473,024 params
Class/BBox Head                          | [92mALL TRAINABLE[0m | 23,644 / 23,644 params
--------------------------------------------------------------------------------
Total Trainable Params: 8,438,620
================================================================================


================================================================================
Parameter Status Check:
================================================================================
RGB Encoder: 15,780,864 params, 7,890,432 trainable
Decoder: 9,473,024 params, 0 trainable
================================================================================

Start training
Epoch: [0] Total time: 0:00:13 (0.2605 s / it)
Epoch [0] Train - Loss: 11.4010, Class Error: 49.22
Test: Total time: 0:00:17 (0.3563 s / it)
Accumulating evaluation results...
DONE (t=0.15s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
coco_evaluator.coco_eval['bbox'].stats: [0.44780594 0.66938753 0.47028038 0.16905428 0.47934902 0.6849046
 0.36860438 0.52624069 0.56359915 0.23854154 0.58756402 0.7969491 ]
Epoch [0] Val - AP: 0.448, AP50: 0.669, AP75: 0.470, AR: 0.564, Loss: 8.2715
Validation score increased (-100000.000000 --> 0.447806).  Saving model ...
Training time 0:00:31
